{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa759d9",
   "metadata": {},
   "source": [
    "# Visualizaci√≥n mejorada de la segmentaci√≥n urbana-rural-vegetaci√≥n\n",
    "\n",
    "Este notebook es una continuaci√≥n del an√°lisis de segmentaci√≥n urbana realizado en el notebook `01_exploration.ipynb`. Aqu√≠ nos centraremos espec√≠ficamente en mejorar las visualizaciones de la segmentaci√≥n de √°reas urbanas, rurales y vegetaci√≥n, asegurando que los elementos visuales est√©n bien distribuidos y no se superpongan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importar librer√≠as necesarias\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import color\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Asegurarse que las figuras se muestran con alta resoluci√≥n\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente (incluyendo scikit-image y cv2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fba19",
   "metadata": {},
   "source": [
    "## Configuraci√≥n inicial y carga de datos\n",
    "\n",
    "En esta secci√≥n, vamos a configurar las rutas necesarias y cargar los datos generados en el notebook anterior. Primero necesitamos cargar los resultados de segmentaci√≥n desde el notebook original para poder trabajar con ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a22b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Configuraci√≥n y Pipeline de Segmentaci√≥n Avanzada con Post-procesamiento\n",
    "\n",
    "# --- Parte 1: Configuraci√≥n de Rutas y Carga de Datos ---\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage import morphology\n",
    "\n",
    "# Configurar rutas\n",
    "project_root = Path(os.getcwd()).parent\n",
    "data_path = project_root / \"data\"\n",
    "raw_data_path = data_path / \"raw\"\n",
    "results_path = project_root / \"results\"\n",
    "figures_path = project_root / \"figures\"\n",
    "\n",
    "# Crear directorios si no existen\n",
    "results_path.mkdir(exist_ok=True)\n",
    "figures_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Rutas configuradas:\")\n",
    "print(f\"  ‚Ä¢ Datos sin procesar: {raw_data_path}\")\n",
    "\n",
    "# Listar im√°genes disponibles\n",
    "image_files = sorted([f for f in raw_data_path.glob(\"*.jpg\")])\n",
    "print(f\"\\nüìÅ Im√°genes disponibles: {len(image_files)} archivos\")\n",
    "for img_file in image_files[:5]:\n",
    "    print(f\"  ‚Ä¢ {img_file.name}\")\n",
    "if len(image_files) > 5:\n",
    "    print(f\"  ‚Ä¢ ... y {len(image_files) - 5} m√°s\")\n",
    "\n",
    "# Funci√≥n para cargar imagen (no cambia)\n",
    "def cargar_imagen(imagen_path, target_size=(400, 400)):\n",
    "    \"\"\"Carga una imagen y la redimensiona al tama√±o objetivo\"\"\"\n",
    "    try:\n",
    "        img = Image.open(imagen_path)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize(target_size)\n",
    "        return np.array(img) / 255.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando {imagen_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Parte 2: Pipeline de Segmentaci√≥n Avanzada (Inspirado en SLEUTH) ---\n",
    "\n",
    "def extraer_features_hibridas(img_rgb):\n",
    "    \"\"\"\n",
    "    Extrae un conjunto SELECTIVO de caracter√≠sticas que realmente aportan valor.\n",
    "    Features: [R, G, B, NDVI] - Solo 4 caracter√≠sticas bien elegidas\n",
    "    \"\"\"\n",
    "    r = img_rgb[:, :, 0].astype(float)\n",
    "    g = img_rgb[:, :, 1].astype(float)\n",
    "    b = img_rgb[:, :, 2].astype(float)\n",
    "    \n",
    "    # NDVI aproximado - LA √öNICA caracter√≠stica adicional que realmente aporta\n",
    "    epsilon = 1e-6\n",
    "    ndvi = (g - r) / (g + r + epsilon)\n",
    "    \n",
    "    # Apilar SOLO las caracter√≠sticas que funcionan\n",
    "    features = np.stack([r, g, b, ndvi], axis=-1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def segmentar_con_metodo_hibrido(img_rgb, usar_solo_rgb=False):\n",
    "    \"\"\"\n",
    "    M√©todo h√≠brido MEJORADO: RGB como base + NDVI selectivo + par√°metros optimizados\n",
    "    \"\"\"\n",
    "    h, w, _ = img_rgb.shape\n",
    "    \n",
    "    if usar_solo_rgb:\n",
    "        # M√©todo RGB puro con escalado cuidadoso\n",
    "        pixels = img_rgb.reshape(-1, 3)\n",
    "        scaler = StandardScaler()\n",
    "        pixels_scaled = scaler.fit_transform(pixels)\n",
    "        n_features = 3\n",
    "    else:\n",
    "        # M√©todo h√≠brido con NDVI pero escalado balanceado\n",
    "        features = extraer_features_hibridas(img_rgb)\n",
    "        pixels = features.reshape(-1, features.shape[-1])\n",
    "        \n",
    "        # Escalado m√°s cuidadoso - darle m√°s peso a RGB\n",
    "        scaler = StandardScaler()\n",
    "        pixels_scaled = scaler.fit_transform(pixels)\n",
    "        \n",
    "        # Rebalancear: RGB tiene peso normal, NDVI peso reducido\n",
    "        pixels_scaled[:, 3] = pixels_scaled[:, 3] * 0.7  # Reducir influencia del NDVI\n",
    "        n_features = 4\n",
    "    \n",
    "    # K-means con par√°metros optimizados para mejor convergencia\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=3, \n",
    "        random_state=42, \n",
    "        n_init=25,  # M√°s intentos\n",
    "        max_iter=400,  # M√°s iteraciones\n",
    "        tol=1e-6,  # Mayor precisi√≥n\n",
    "        algorithm='elkan'  # Algoritmo m√°s eficiente\n",
    "    )\n",
    "    \n",
    "    labels = kmeans.fit_predict(pixels_scaled)\n",
    "    labels = labels.reshape(h, w)\n",
    "    \n",
    "    # Centroides en espacio original\n",
    "    centroides = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "    \n",
    "    # Confianza mejorada\n",
    "    distances = kmeans.transform(pixels_scaled)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "    max_distance = np.max(min_distances)\n",
    "    \n",
    "    # Confianza normalizada m√°s suave\n",
    "    confidence = 1.0 - (min_distances / (max_distance + 1e-6))\n",
    "    confidence = np.clip(confidence, 0.3, 1.0)  # Limitar rango para mejor visualizaci√≥n\n",
    "    confidence = confidence.reshape(h, w)\n",
    "    \n",
    "    return labels, centroides, confidence, n_features\n",
    "\n",
    "def post_procesar_segmentacion(labels, confidence, ventana=5):\n",
    "    \"\"\"\n",
    "    Post-procesamiento MEJORADO que preserva estructura urbana y mejora conectividad\n",
    "    \"\"\"\n",
    "    h, w = labels.shape\n",
    "    labels_mejorados = labels.copy()\n",
    "    \n",
    "    # M√°scara de alta confianza - estas √°reas no se modifican\n",
    "    alta_confianza = confidence > 0.7\n",
    "    \n",
    "    # 1. Filtro de mediana SELECTIVO - solo en √°reas de baja confianza\n",
    "    mascara_filtrar = confidence < 0.5\n",
    "    if np.any(mascara_filtrar):\n",
    "        labels_filtrados = median_filter(labels_mejorados, size=3)\n",
    "        labels_mejorados = np.where(mascara_filtrar, labels_filtrados, labels_mejorados)\n",
    "    \n",
    "    # 2. Tratamiento espec√≠fico por clase\n",
    "    for clase in [1, 2, 3]:\n",
    "        mask_clase = (labels_mejorados == clase)\n",
    "        \n",
    "        if np.any(mask_clase):\n",
    "            # Par√°metros adaptativos por clase\n",
    "            if clase == 1:  # Urbano - preservar detalles, mejorar conectividad\n",
    "                min_size = 30  # Menor tama√±o m√≠nimo para capturar detalles urbanos\n",
    "                hole_size = 40\n",
    "                kernel_size = 7  # Kernel m√°s grande para conectar √°reas urbanas\n",
    "                umbral_mayoria = 0.4  # Menos estricto para √°reas urbanas\n",
    "                \n",
    "                # Operaci√≥n especial: conectar √°reas urbanas cercanas\n",
    "                kernel_conectar = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "                mask_expandida = cv2.morphologyEx(mask_clase.astype(np.uint8), \n",
    "                                                cv2.MORPH_CLOSE, kernel_conectar)\n",
    "                \n",
    "                # Solo aplicar conexi√≥n donde hay evidencia (confianza media)\n",
    "                mask_aplicar = confidence > 0.4\n",
    "                mask_clase = np.where(mask_aplicar & (mask_expandida == 1), True, mask_clase)\n",
    "                \n",
    "            elif clase == 2:  # Vegetaci√≥n - preservar formas naturales\n",
    "                min_size = 40\n",
    "                hole_size = 25\n",
    "                kernel_size = 5\n",
    "                umbral_mayoria = 0.5\n",
    "                \n",
    "            else:  # Rural - operaciones m√°s amplias\n",
    "                min_size = 60\n",
    "                hole_size = 50\n",
    "                kernel_size = 7\n",
    "                umbral_mayoria = 0.6\n",
    "            \n",
    "            # Aplicar limpieza morfol√≥gica\n",
    "            mask_limpia = morphology.remove_small_objects(mask_clase, min_size=min_size)\n",
    "            mask_limpia = morphology.remove_small_holes(mask_limpia, area_threshold=hole_size)\n",
    "            \n",
    "            # Solo aplicar cambios en √°reas de baja/media confianza\n",
    "            mask_cambios = confidence < 0.8\n",
    "            labels_mejorados = np.where(mask_cambios & mask_limpia, clase, \n",
    "                                      np.where(mask_cambios & mask_clase & ~mask_limpia, 0, labels_mejorados))\n",
    "    \n",
    "    # 3. Filtro de mayor√≠a local ADAPTATIVO\n",
    "    for clase in [1, 2, 3]:\n",
    "        mask = (labels_mejorados == clase).astype(float)\n",
    "        kernel = np.ones((ventana, ventana))\n",
    "        vecinos = ndimage.convolve(mask, kernel, mode='constant')\n",
    "        \n",
    "        # Umbral adaptativo por clase\n",
    "        if clase == 1:  # Urbano - menos restrictivo\n",
    "            threshold = ventana * ventana * 0.35\n",
    "        elif clase == 2:  # Vegetaci√≥n\n",
    "            threshold = ventana * ventana * 0.45\n",
    "        else:  # Rural\n",
    "            threshold = ventana * ventana * 0.55\n",
    "        \n",
    "        strong_regions = vecinos > threshold\n",
    "        \n",
    "        # Solo aplicar en √°reas de baja confianza\n",
    "        mask_aplicar = confidence < 0.6\n",
    "        strong_regions = strong_regions & mask_aplicar\n",
    "        \n",
    "        labels_mejorados[strong_regions] = clase\n",
    "    \n",
    "    # 4. Reasignaci√≥n inteligente de p√≠xeles sin asignar\n",
    "    pixels_sin_asignar = (labels_mejorados == 0)\n",
    "    if np.any(pixels_sin_asignar):\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if labels_mejorados[i, j] == 0:\n",
    "                    # Ventana adaptativa seg√∫n la confianza local\n",
    "                    radio = 3 if confidence[i, j] < 0.3 else 2\n",
    "                    i_min, i_max = max(0, i-radio), min(h, i+radio+1)\n",
    "                    j_min, j_max = max(0, j-radio), min(w, j+radio+1)\n",
    "                    \n",
    "                    vecindario = labels_mejorados[i_min:i_max, j_min:j_max]\n",
    "                    vecindario_valido = vecindario[vecindario > 0]\n",
    "                    \n",
    "                    if len(vecindario_valido) > 0:\n",
    "                        # Considerar confianza del vecindario\n",
    "                        confianza_vecindario = confidence[i_min:i_max, j_min:j_max]\n",
    "                        peso_confianza = confianza_vecindario[vecindario > 0]\n",
    "                        \n",
    "                        # Voto ponderado por confianza\n",
    "                        clases_unicas = np.unique(vecindario_valido)\n",
    "                        mejor_clase = clases_unicas[0]\n",
    "                        mejor_peso = 0\n",
    "                        \n",
    "                        for clase_cand in clases_unicas:\n",
    "                            peso_clase = np.sum(peso_confianza[vecindario_valido == clase_cand])\n",
    "                            if peso_clase > mejor_peso:\n",
    "                                mejor_peso = peso_clase\n",
    "                                mejor_clase = clase_cand\n",
    "                        \n",
    "                        labels_mejorados[i, j] = mejor_clase\n",
    "                    else:\n",
    "                        labels_mejorados[i, j] = 3  # Por defecto, rural\n",
    "    \n",
    "    return labels_mejorados\n",
    "\n",
    "def clasificar_hibrido_inteligente(centroides, img_rgb, n_features):\n",
    "    \"\"\"\n",
    "    Clasificaci√≥n h√≠brida CORREGIDA - Volviendo a criterios m√°s precisos\n",
    "    \"\"\"\n",
    "    clasificacion = {}\n",
    "    print(\"üß† An√°lisis h√≠brido RGB + NDVI (versi√≥n corregida):\")\n",
    "    \n",
    "    # Calcular estad√≠sticas globales m√°s conservadoras\n",
    "    r_global = img_rgb[:, :, 0].flatten()\n",
    "    g_global = img_rgb[:, :, 1].flatten()\n",
    "    b_global = img_rgb[:, :, 2].flatten()\n",
    "    \n",
    "    # Umbrales m√°s restrictivos\n",
    "    brillo_percentil_alto = np.percentile((r_global + g_global + b_global) / 3, 85)  # M√°s alto\n",
    "    verdor_percentil_alto = np.percentile(g_global - (r_global + b_global) / 2, 80)  # M√°s alto\n",
    "    \n",
    "    print(f\"  üìä Umbrales conservadores: Brillo>{brillo_percentil_alto:.3f}, Verdor>{verdor_percentil_alto:.3f}\")\n",
    "    \n",
    "    for i, centroide in enumerate(centroides):\n",
    "        r, g, b = centroide[0], centroide[1], centroide[2]\n",
    "        \n",
    "        # Calcular caracter√≠sticas\n",
    "        brillo = (r + g + b) / 3\n",
    "        verdor_rgb = g - (r + b) / 2\n",
    "        saturacion_rgb = np.std([r, g, b])\n",
    "        \n",
    "        if n_features > 3:\n",
    "            ndvi = centroide[3]\n",
    "            print(f\"  Cluster {i}: R={r:.3f}, G={g:.3f}, B={b:.3f}, NDVI={ndvi:.3f}\")\n",
    "            print(f\"             Brillo={brillo:.3f}, Verdor={verdor_rgb:.3f}, Saturaci√≥n={saturacion_rgb:.3f}\")\n",
    "        else:\n",
    "            ndvi = (g - r) / (g + r + 0.001)\n",
    "            print(f\"  Cluster {i}: R={r:.3f}, G={g:.3f}, B={b:.3f}, NDVI_calc={ndvi:.3f}\")\n",
    "            print(f\"             Brillo={brillo:.3f}, Verdor={verdor_rgb:.3f}, Saturaci√≥n={saturacion_rgb:.3f}\")\n",
    "        \n",
    "        # L√ìGICA DE CLASIFICACI√ìN BALANCEADA\n",
    "        \n",
    "        # 1. Vegetaci√≥n: Criterios m√°s flexibles pero a√∫n precisos\n",
    "        if (verdor_rgb > 0.035 and ndvi > 0.08 and g > r) or (ndvi > 0.15):\n",
    "            clase = 2\n",
    "            tipo = \"Vegetaci√≥n (Verde + NDVI)\"\n",
    "            \n",
    "        # 2. Urbano: Criterios espec√≠ficos pero no demasiado restrictivos\n",
    "        elif (\n",
    "            # Criterio 1: Colores claros (edificios brillantes)\n",
    "            brillo > brillo_percentil_alto or\n",
    "            # Criterio 2: Grises neutros espec√≠ficos (infraestructura)\n",
    "            (abs(r - g) < 0.06 and abs(g - b) < 0.06 and brillo > 0.42) or\n",
    "            # Criterio 3: Baja saturaci√≥n con brillo alto (concreto/asfalto)\n",
    "            (saturacion_rgb < 0.1 and brillo > 0.47)\n",
    "        ):\n",
    "            clase = 1\n",
    "            tipo = \"Urbano (Infraestructura)\"\n",
    "            \n",
    "        # 3. Rural: Todo lo dem√°s\n",
    "        else:\n",
    "            clase = 3\n",
    "            tipo = \"Rural (Tierra, mixto)\"\n",
    "        \n",
    "        clasificacion[i] = clase\n",
    "        print(f\"    ‚Üí {tipo}\")\n",
    "    \n",
    "    # REBALANCEO INTELIGENTE - Asegurar m√≠nima representaci√≥n\n",
    "    clases_presentes = set(clasificacion.values())\n",
    "    print(f\"  üìä Clases detectadas inicialmente: {sorted(clases_presentes)}\")\n",
    "    \n",
    "    # Si falta vegetaci√≥n, buscar el cluster m√°s verde\n",
    "    if 2 not in clases_presentes:\n",
    "        print(\"  üå± Buscando vegetaci√≥n...\")\n",
    "        clusters_info = []\n",
    "        for i, centroide in enumerate(centroides):\n",
    "            r, g, b = centroide[0], centroide[1], centroide[2]\n",
    "            verdor = g - (r + b) / 2\n",
    "            ndvi_val = centroide[3] if n_features > 3 else (g - r) / (g + r + 0.001)\n",
    "            \n",
    "            clusters_info.append({\n",
    "                'id': i,\n",
    "                'verdor': verdor,\n",
    "                'ndvi': ndvi_val,\n",
    "                'g_value': g\n",
    "            })\n",
    "        \n",
    "        # Buscar el cluster m√°s verde que no sea urbano\n",
    "        candidatos_vegetacion = [c for c in clusters_info if clasificacion[c['id']] != 1]\n",
    "        if candidatos_vegetacion:\n",
    "            mejor_vegetacion = max(candidatos_vegetacion, key=lambda x: x['ndvi'])\n",
    "            if mejor_vegetacion['ndvi'] > 0.02:  # M√≠nimo umbral\n",
    "                clasificacion[mejor_vegetacion['id']] = 2\n",
    "                print(f\"    ‚Üí Cluster {mejor_vegetacion['id']} ‚Üí Vegetaci√≥n (NDVI: {mejor_vegetacion['ndvi']:.3f})\")\n",
    "    \n",
    "    # Si solo hay una clase, forzar diversidad m√≠nima\n",
    "    if len(clases_presentes) == 1:\n",
    "        print(\"  üîß Forzando diversidad m√≠nima...\")\n",
    "        \n",
    "        clusters_info = []\n",
    "        for i, centroide in enumerate(centroides):\n",
    "            r, g, b = centroide[0], centroide[1], centroide[2]\n",
    "            brillo = (r + g + b) / 3\n",
    "            verdor = g - (r + b) / 2\n",
    "            ndvi_val = centroide[3] if n_features > 3 else (g - r) / (g + r + 0.001)\n",
    "            \n",
    "            clusters_info.append({\n",
    "                'id': i,\n",
    "                'brillo': brillo,\n",
    "                'verdor': verdor,\n",
    "                'ndvi': ndvi_val\n",
    "            })\n",
    "        \n",
    "        clusters_ordenados = sorted(clusters_info, key=lambda x: x['brillo'])\n",
    "        \n",
    "        # Asignar diversidad b√°sica\n",
    "        if len(clusters_ordenados) >= 3:\n",
    "            clasificacion[clusters_ordenados[0]['id']] = 3  # M√°s oscuro = Rural\n",
    "            clasificacion[clusters_ordenados[1]['id']] = 2  # Intermedio = Vegetaci√≥n\n",
    "            clasificacion[clusters_ordenados[2]['id']] = 1  # M√°s claro = Urbano\n",
    "        elif len(clusters_ordenados) == 2:\n",
    "            clasificacion[clusters_ordenados[0]['id']] = 3  # Rural\n",
    "            clasificacion[clusters_ordenados[1]['id']] = 1  # Urbano\n",
    "    \n",
    "    print(f\"  ‚úÖ Clasificaci√≥n final: {sorted(clasificacion.items())}\")\n",
    "    return clasificacion\n",
    "\n",
    "def post_procesar_suave(labels, ventana=3):\n",
    "    \"\"\"\n",
    "    Post-procesamiento M√ÅS SUAVE que preserva m√°s detalles urbanos\n",
    "    \"\"\"\n",
    "    labels_mejorados = labels.copy()\n",
    "    \n",
    "    # 1. Solo filtro de mediana MUY suave para eliminar p√≠xeles aislados\n",
    "    labels_mejorados = median_filter(labels_mejorados, size=2)\n",
    "    \n",
    "    # 2. Eliminar SOLO objetos muy peque√±os (menos de 20 p√≠xeles)\n",
    "    for clase in [1, 2, 3]:\n",
    "        mask = (labels_mejorados == clase)\n",
    "        mask_limpia = morphology.remove_small_objects(mask, min_size=20)\n",
    "        # Solo cambiar p√≠xeles de objetos MUY peque√±os\n",
    "        pixels_a_cambiar = mask & ~mask_limpia\n",
    "        \n",
    "        # Reasignar a la clase m√°s com√∫n en el vecindario inmediato\n",
    "        coords = np.where(pixels_a_cambiar)\n",
    "        for i, j in zip(coords[0], coords[1]):\n",
    "            # Vecindario 3x3\n",
    "            i_min, i_max = max(0, i-1), min(labels.shape[0], i+2)\n",
    "            j_min, j_max = max(0, j-1), min(labels.shape[1], j+2)\n",
    "            vecindario = labels_mejorados[i_min:i_max, j_min:j_max]\n",
    "            vecindario_valido = vecindario[vecindario != labels_mejorados[i, j]]\n",
    "            \n",
    "            if len(vecindario_valido) > 0:\n",
    "                nueva_clase = np.bincount(vecindario_valido).argmax()\n",
    "                labels_mejorados[i, j] = nueva_clase\n",
    "    \n",
    "    return labels_mejorados\n",
    "\n",
    "def ejecutar_pipeline_hibrido(imagen_path, usar_solo_rgb=False):\n",
    "    \"\"\"\n",
    "    Pipeline h√≠brido optimizado: RGB + NDVI selectivo + post-procesamiento suave\n",
    "    \"\"\"\n",
    "    print(f\"\\nüñºÔ∏è  Pipeline H√≠brido: {imagen_path.name}\")\n",
    "    print(f\"     Modo: {'Solo RGB' if usar_solo_rgb else 'RGB + NDVI selectivo'}\")\n",
    "    \n",
    "    img_rgb = cargar_imagen(imagen_path)\n",
    "    if img_rgb is None:\n",
    "        return None\n",
    "    \n",
    "    # Segmentaci√≥n h√≠brida\n",
    "    labels, centroides, confidence, n_features = segmentar_con_metodo_hibrido(img_rgb, usar_solo_rgb)\n",
    "    \n",
    "    # Clasificaci√≥n inteligente\n",
    "    clasificacion = clasificar_hibrido_inteligente(centroides, img_rgb, n_features)\n",
    "    \n",
    "    # Mapear etiquetas\n",
    "    labels_semanticos = np.zeros_like(labels)\n",
    "    for cluster_id, clase_id in clasificacion.items():\n",
    "        labels_semanticos[labels == cluster_id] = clase_id\n",
    "    \n",
    "    # Post-procesamiento con funci√≥n mejorada (no el suave que es muy b√°sico)\n",
    "    print(\"üîß Post-procesamiento inteligente...\")\n",
    "    labels_finales = post_procesar_segmentacion(labels_semanticos, confidence)\n",
    "    \n",
    "    print(\"‚úÖ Pipeline h√≠brido completado.\")\n",
    "    \n",
    "    return {\n",
    "        'rgb': img_rgb, 'labels': labels_finales, 'confidence': confidence,\n",
    "        'year': int(imagen_path.stem.split('_')[-1]), 'method': 'RGB' if usar_solo_rgb else 'H√≠brido'\n",
    "    }\n",
    "\n",
    "# --- Ejecuci√≥n de demostraci√≥n ---\n",
    "\n",
    "# Definir las clases y colores (esto no cambia)\n",
    "class_names = [\"Urbano\", \"Vegetaci√≥n\", \"Rural\"]\n",
    "class_colors = [\n",
    "    [0.8, 0.1, 0.1],  # Rojo para √°reas urbanas\n",
    "    [0.1, 0.6, 0.1],  # Verde para vegetaci√≥n\n",
    "    [0.8, 0.7, 0.3]   # Beige para rural\n",
    "]\n",
    "\n",
    "# --- Comparaci√≥n de m√©todos ---\n",
    "\n",
    "imagen_seleccionada = image_files[-1]  # A√±o 2004\n",
    "\n",
    "print(\"üî¨ COMPARACI√ìN DE M√âTODOS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# M√©todo 1: Solo RGB (el que funcionaba bien originalmente)\n",
    "resultado_rgb = ejecutar_pipeline_hibrido(imagen_seleccionada, usar_solo_rgb=True)\n",
    "\n",
    "# M√©todo 2: H√≠brido RGB + NDVI selectivo\n",
    "resultado_hibrido = ejecutar_pipeline_hibrido(imagen_seleccionada, usar_solo_rgb=False)\n",
    "\n",
    "# Mostrar comparaci√≥n\n",
    "if resultado_rgb and resultado_hibrido:\n",
    "    print(\"\\nüìä COMPARACI√ìN DE RESULTADOS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'M√©todo':<15} {'Urbano%':<10} {'Vegetaci√≥n%':<12} {'Rural%':<10}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for resultado, nombre in [(resultado_rgb, 'Solo RGB'), (resultado_hibrido, 'RGB+NDVI')]:\n",
    "        stats = {}\n",
    "        for i, name in enumerate(class_names, 1):\n",
    "            count = np.sum(resultado['labels'] == i)\n",
    "            percentage = 100.0 * count / resultado['labels'].size\n",
    "            stats[name.lower()] = percentage\n",
    "        \n",
    "        print(f\"{nombre:<15} {stats['urbano']:<10.1f} {stats['vegetaci√≥n']:<12.1f} {stats['rural']:<10.1f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Usar el mejor resultado para visualizaci√≥n\n",
    "    print(\"\\nüéØ Seleccionando el mejor resultado...\")\n",
    "    \n",
    "    # Criterio: preferir el que detecte vegetaci√≥n Y tenga distribuci√≥n m√°s equilibrada\n",
    "    rgb_veg = sum(resultado_rgb['labels'].flatten() == 2) / resultado_rgb['labels'].size\n",
    "    hyb_veg = sum(resultado_hibrido['labels'].flatten() == 2) / resultado_hibrido['labels'].size\n",
    "    \n",
    "    if hyb_veg > rgb_veg and hyb_veg > 0.05:  # Al menos 5% de vegetaci√≥n detectada\n",
    "        mejor_resultado = resultado_hibrido\n",
    "        print(\"‚Üí M√©todo H√≠brido RGB+NDVI seleccionado (mejor detecci√≥n de vegetaci√≥n)\")\n",
    "    else:\n",
    "        mejor_resultado = resultado_rgb\n",
    "        print(\"‚Üí M√©todo RGB puro seleccionado (m√°s confiable)\")\n",
    "    \n",
    "    # Actualizar variables globales\n",
    "    sample_rgb = mejor_resultado['rgb']\n",
    "    sample_labels = mejor_resultado['labels']\n",
    "    sample_confidence = mejor_resultado['confidence']\n",
    "    \n",
    "    print(f\"\\nüìä Distribuci√≥n final ({mejor_resultado['method']}):\")\n",
    "    for i, name in enumerate(class_names, 1):\n",
    "        count = np.sum(sample_labels == i)\n",
    "        percentage = 100.0 * count / sample_labels.size\n",
    "        print(f\"    - {name}: {count:,} p√≠xeles ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782036e6",
   "metadata": {},
   "source": [
    "## Visualizaci√≥n mejorada de la segmentaci√≥n\n",
    "\n",
    "Ahora vamos a crear una visualizaci√≥n mejorada que muestre claramente la segmentaci√≥n urbano-rural-vegetaci√≥n. Vamos a asegurarnos de que todos los elementos est√©n bien organizados y no se superpongan, utilizando un layout m√°s espacioso y claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d309be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualizaci√≥n mejorada de la segmentaci√≥n urbano-rural-vegetaci√≥n\n",
    "\n",
    "def crear_mapa_coloreado(labels, colors):\n",
    "    \"\"\"Crea un mapa RGB a partir de etiquetas y colores\"\"\"\n",
    "    h, w = labels.shape\n",
    "    colored_map = np.zeros((h, w, 3))\n",
    "    for i, color in enumerate(colors, 1):\n",
    "        mask = (labels == i)\n",
    "        colored_map[mask] = color\n",
    "    return colored_map\n",
    "\n",
    "# Crear el mapa coloreado\n",
    "urban_rural_map = crear_mapa_coloreado(sample_labels, class_colors)\n",
    "\n",
    "# Configuraci√≥n de la figura con mayor espacio y mejor distribuci√≥n\n",
    "plt.figure(figsize=(22, 16))\n",
    "\n",
    "# Crear un grid m√°s espacioso para evitar superposiciones\n",
    "gs = gridspec.GridSpec(3, 4, height_ratios=[2, 2, 1], width_ratios=[1, 1, 1, 1])\n",
    "\n",
    "# 1. Mapa segmentado completo (panel grande a la izquierda)\n",
    "ax1 = plt.subplot(gs[0:2, 0:2])\n",
    "ax1.imshow(urban_rural_map)\n",
    "ax1.set_title(\"Segmentaci√≥n urbano-rural-vegetaci√≥n\", fontsize=18, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# 2. Imagen original RGB (arriba a la derecha)\n",
    "ax2 = plt.subplot(gs[0, 2])\n",
    "ax2.imshow(sample_rgb)\n",
    "ax2.set_title(\"Imagen original (RGB)\", fontsize=16, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "# 3. Mapa de confianza (centro a la derecha)\n",
    "ax3 = plt.subplot(gs[0, 3])\n",
    "confidence_vis = ax3.imshow(sample_confidence, cmap='RdYlGn', vmin=0.5, vmax=1.0)\n",
    "ax3.set_title(\"Mapa de confianza\", fontsize=16, fontweight='bold')\n",
    "ax3.axis('off')\n",
    "\n",
    "# Agregar colorbar para el mapa de confianza\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(confidence_vis, cax=cax, orientation='vertical')\n",
    "cbar.set_label('Nivel de confianza', fontsize=12)\n",
    "\n",
    "# 4. Superposici√≥n con transparencia (abajo a la derecha)\n",
    "ax4 = plt.subplot(gs[1, 2:])\n",
    "overlay = urban_rural_map.copy()\n",
    "alpha = 0.6  # Transparencia\n",
    "for i in range(3):\n",
    "    overlay[:,:,i] = overlay[:,:,i] * alpha + sample_rgb[:,:,i] * (1-alpha)\n",
    "ax4.imshow(overlay)\n",
    "ax4.set_title(\"Superposici√≥n de clases sobre imagen\", fontsize=16, fontweight='bold')\n",
    "ax4.axis('off')\n",
    "\n",
    "# 5. Panel de estad√≠sticas y gr√°fico de pastel (abajo)\n",
    "ax5 = plt.subplot(gs[2, 0:2])\n",
    "ax5.axis('off')\n",
    "\n",
    "# Crear DataFrame para estad√≠sticas\n",
    "stats_data = []\n",
    "for i, name in enumerate(class_names, 1):\n",
    "    count = np.sum(sample_labels == i)\n",
    "    percentage = 100.0 * count / sample_labels.size\n",
    "    avg_conf = np.mean(sample_confidence[sample_labels == i])\n",
    "    stats_data.append({\n",
    "        'Clase': name,\n",
    "        'P√≠xeles': count,\n",
    "        'Porcentaje': percentage,\n",
    "        'Confianza': avg_conf\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats_data)\n",
    "\n",
    "# Crear tabla de estad√≠sticas\n",
    "cell_text = []\n",
    "for i, row in df_stats.iterrows():\n",
    "    cell_text.append([\n",
    "        row['Clase'], \n",
    "        f\"{row['P√≠xeles']:,}\", \n",
    "        f\"{row['Porcentaje']:.1f}%\", \n",
    "        f\"{row['Confianza']:.3f}\"\n",
    "    ])\n",
    "\n",
    "ax5.table(\n",
    "    cellText=cell_text,\n",
    "    colLabels=['Clase', 'P√≠xeles', 'Porcentaje', 'Confianza Media'],\n",
    "    loc='center',\n",
    "    cellLoc='center',\n",
    "    bbox=[0.1, 0.3, 0.8, 0.5]  # [left, bottom, width, height]\n",
    ")\n",
    "ax5.set_title(\"Estad√≠sticas de clases\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# 6. Gr√°fico de pastel (abajo a la derecha)\n",
    "ax6 = plt.subplot(gs[2, 2:])\n",
    "\n",
    "# Obtener valores para el gr√°fico\n",
    "sizes = df_stats['Porcentaje'].values\n",
    "explode = (0.1, 0.0, 0.0)  # Explotar la porci√≥n urbana\n",
    "\n",
    "wedges, texts, autotexts = ax6.pie(\n",
    "    sizes, \n",
    "    explode=explode,\n",
    "    labels=class_names, \n",
    "    colors=class_colors,\n",
    "    autopct='%1.1f%%',\n",
    "    shadow=True,\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 14},\n",
    "    wedgeprops={'edgecolor': 'w', 'linewidth': 1}\n",
    ")\n",
    "\n",
    "for text in texts + autotexts:\n",
    "    text.set_fontweight('bold')\n",
    "\n",
    "ax6.set_title('Distribuci√≥n de coberturas', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Crear leyenda separada con muestras de colores m√°s grandes\n",
    "legend_elements = []\n",
    "for i, name in enumerate(class_names):\n",
    "    legend_elements.append(\n",
    "        Patch(facecolor=class_colors[i], \n",
    "              edgecolor='black', \n",
    "              label=f\"{name} ({df_stats['Porcentaje'].values[i]:.1f}%)\")\n",
    "    )\n",
    "\n",
    "# A√±adir leyenda en un lugar separado para evitar superposiciones\n",
    "legend = plt.figlegend(\n",
    "    handles=legend_elements,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, 0.06),\n",
    "    fontsize=14,\n",
    "    frameon=True,\n",
    "    ncol=3\n",
    ")\n",
    "\n",
    "# T√≠tulo global\n",
    "plt.suptitle(\"SEGMENTACI√ìN URBANO-RURAL-VEGETACI√ìN\", \n",
    "             fontsize=22, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.08, 1, 0.95])  # Ajuste para evitar superposiciones\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)  # A√±adir m√°s espacio entre subplots\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Guardar la figura en alta resoluci√≥n\n",
    "plt.savefig(figures_path / \"segmentacion_urbano_rural_vegetacion.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Visualizaci√≥n mejorada completada y guardada en el directorio 'figures'\")\n",
    "print(\"La visualizaci√≥n muestra claramente las diferentes categor√≠as sin elementos superpuestos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30b310",
   "metadata": {},
   "source": [
    "## üß¨ Explicaci√≥n del Pipeline de Segmentaci√≥n H√≠brida\n",
    "\n",
    "El m√©todo que hemos desarrollado es un pipeline h√≠brido y adaptativo dise√±ado para maximizar la precisi√≥n en la clasificaci√≥n de coberturas de suelo. A continuaci√≥n se detalla cada paso del proceso:\n",
    "\n",
    "### 1. Carga y Pre-procesamiento de Imagen\n",
    "- **Entrada**: Imagen satelital en formato JPG.\n",
    "- **Proceso**: La imagen se carga y se convierte al espacio de color RGB. Para estandarizar el an√°lisis, todas las im√°genes se redimensionan a un tama√±o uniforme de 400x400 p√≠xeles y sus valores de color se normalizan en un rango de 0 a 1.\n",
    "\n",
    "### 2. Extracci√≥n de Caracter√≠sticas H√≠bridas\n",
    "En lugar de usar solo los canales RGB, creamos un conjunto de \"caracter√≠sticas\" m√°s rico para cada p√≠xel, lo que permite al algoritmo tomar decisiones m√°s informadas.\n",
    "- **Canales RGB**: Los valores normalizados de Rojo, Verde y Azul son las caracter√≠sticas base.\n",
    "- **NDVI (√çndice de Vegetaci√≥n de Diferencia Normalizada)**: Calculamos una aproximaci√≥n del NDVI usando la f√≥rmula `(Verde - Rojo) / (Verde + Rojo)`. Esta es la caracter√≠stica m√°s importante para discriminar vegetaci√≥n de otras superficies.\n",
    "- **Resultado**: Cada p√≠xel se convierte en un vector de 4 dimensiones: `[R, G, B, NDVI]`.\n",
    "\n",
    "### 3. Clustering con K-Means Optimizado\n",
    "El objetivo es agrupar los 160,000 p√≠xeles de la imagen en 3 grupos (clusters) bas√°ndose en sus caracter√≠sticas.\n",
    "- **Algoritmo**: Se utiliza K-Means con par√°metros optimizados para mayor estabilidad y precisi√≥n (`n_init=25`, `max_iter=400`, `algorithm='elkan'`).\n",
    "- **Balance de Caracter√≠sticas**: Para evitar que el NDVI domine la clasificaci√≥n (lo que podr√≠a causar que todo se clasifique como vegetaci√≥n o no), su influencia se reduce ligeramente (`peso = 0.7`). Esto permite que las caracter√≠sticas de color RGB sigan siendo el factor principal para √°reas no vegetales.\n",
    "- **Resultado**: Se obtienen 3 clusters y sus \"centroides\", que son los vectores de caracter√≠sticas promedio para cada grupo.\n",
    "\n",
    "### 4. Clasificaci√≥n Sem√°ntica Adaptativa\n",
    "Este es el \"cerebro\" del sistema. Asigna una etiqueta (Urbano, Vegetaci√≥n, Rural) a cada uno de los 3 clusters.\n",
    "- **Umbrales Adaptativos**: En lugar de usar valores fijos, el sistema primero analiza la distribuci√≥n global de brillo y \"verdor\" de la imagen para calcular umbrales din√°micos. Esto hace que el m√©todo sea robusto ante cambios de iluminaci√≥n entre diferentes a√±os.\n",
    "- **L√≥gica de Decisi√≥n Multi-criterio**:\n",
    "  - **Vegetaci√≥n**: Se asigna si un cluster tiene un NDVI y un nivel de \"verdor\" suficientemente altos.\n",
    "  - **Urbano**: Se utiliza un conjunto de reglas para identificar infraestructura. Un cluster se considera urbano si es muy brillante (techos, concreto), si es un gris neutro (asfalto) o si tiene un brillo alto con baja saturaci√≥n de color.\n",
    "  - **Rural**: Es la clase por defecto para todo lo que no es claramente urbano ni vegetaci√≥n (tierra, roca, vegetaci√≥n seca).\n",
    "- **Rebalanceo de Emergencia**: Si la l√≥gica inicial no logra encontrar una de las clases (por ejemplo, en una imagen muy √°rida donde no se detecta vegetaci√≥n), un sistema de seguridad busca el cluster \"m√°s verde\" disponible y lo asigna a Vegetaci√≥n para asegurar que las 3 clases est√©n siempre presentes.\n",
    "\n",
    "### 5. Post-procesamiento Inteligente y Contextual\n",
    "La clasificaci√≥n inicial puede tener \"ruido\" (p√≠xeles aislados mal clasificados). El post-procesamiento lo limpia de forma inteligente.\n",
    "- **Filtro Basado en Confianza**: Se calcula un \"mapa de confianza\" para cada p√≠xel. Las operaciones de limpieza m√°s agresivas solo se aplican en √°reas donde el algoritmo tiene baja confianza, preservando as√≠ los detalles finos en √°reas bien definidas.\n",
    "- **Morfolog√≠a Adaptativa por Clase**: Se aplican diferentes t√©cnicas de limpieza para cada clase. Por ejemplo, para la clase \"Urbano\", se utilizan operaciones que tienden a conectar √°reas cercanas para formar calles o barrios coherentes, mientras que para \"Vegetaci√≥n\" se preservan mejor las formas org√°nicas.\n",
    "- **Reasignaci√≥n Ponderada**: Los p√≠xeles que se eliminan por ser \"ruido\" no se descartan, sino que se reasignan a la clase m√°s probable bas√°ndose en un voto ponderado por la confianza de sus vecinos.\n",
    "\n",
    "### 6. Visualizaci√≥n y Selecci√≥n del Mejor M√©todo\n",
    "Finalmente, el pipeline se ejecuta dos veces: una en modo \"Solo RGB\" y otra en modo \"H√≠brido\".\n",
    "- **Comparaci√≥n**: Se comparan los resultados de ambos m√©todos.\n",
    "- **Selecci√≥n Autom√°tica**: El sistema selecciona autom√°ticamente el resultado del m√©todo h√≠brido si este logra detectar una cantidad razonable de vegetaci√≥n (>5%). De lo contrario, se queda con el resultado del m√©todo \"Solo RGB\", que es m√°s conservador y confiable.\n",
    "- **Resultado Final**: Una imagen de segmentaci√≥n limpia, precisa y contextualizada, junto con estad√≠sticas detalladas de la distribuci√≥n de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a23852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Procesamiento y Visualizaci√≥n en Lote de Todas las Im√°genes\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def procesar_y_guardar_resultados(a√±os_seleccionados=None, mostrar_progreso=True):\n",
    "    \"\"\"\n",
    "    Procesa una selecci√≥n de im√°genes, guarda los resultados y devuelve los datos.\n",
    "    \"\"\"\n",
    "    imagenes_a_procesar = image_files\n",
    "    if a√±os_seleccionados is not None:\n",
    "        imagenes_a_procesar = [f for f in image_files if any(str(a√±o) in f.name for a√±o in a√±os_seleccionados)]\n",
    "    \n",
    "    print(f\"üöÄ Iniciando procesamiento de {len(imagenes_a_procesar)} im√°genes...\")\n",
    "    \n",
    "    resultados_completos = []\n",
    "    tiempo_inicio = time.time()\n",
    "    \n",
    "    for i, imagen_path in enumerate(imagenes_a_procesar):\n",
    "        if mostrar_progreso:\n",
    "            progreso = (i + 1) / len(imagenes_a_procesar) * 100\n",
    "            print(f\"\\\\n[{progreso:.1f}%] Procesando {imagen_path.name}...\")\n",
    "        \n",
    "        # Ejecutar ambos pipelines\n",
    "        resultado_rgb = ejecutar_pipeline_hibrido(imagen_path, usar_solo_rgb=True)\n",
    "        resultado_hibrido = ejecutar_pipeline_hibrido(imagen_path, usar_solo_rgb=False)\n",
    "        \n",
    "        # Seleccionar el mejor resultado\n",
    "        if resultado_rgb and resultado_hibrido:\n",
    "            rgb_veg = np.sum(resultado_rgb['labels'] == 2) / resultado_rgb['labels'].size\n",
    "            hyb_veg = np.sum(resultado_hibrido['labels'] == 2) / resultado_hibrido['labels'].size\n",
    "            \n",
    "            if hyb_veg > rgb_veg and hyb_veg > 0.05:\n",
    "                mejor_resultado = resultado_hibrido\n",
    "            else:\n",
    "                mejor_resultado = resultado_rgb\n",
    "            \n",
    "            resultados_completos.append(mejor_resultado)\n",
    "            print(f\"  ‚Üí Mejor m√©todo: {mejor_resultado['method']}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Error al procesar {imagen_path.name}\")\n",
    "\n",
    "    tiempo_total = time.time() - tiempo_inicio\n",
    "    print(f\"\\\\n‚úÖ Procesamiento completado en {tiempo_total:.1f} segundos.\")\n",
    "    \n",
    "    return resultados_completos\n",
    "\n",
    "# Procesar todas las im√°genes\n",
    "todos_los_resultados = procesar_y_guardar_resultados()\n",
    "\n",
    "# Visualizaci√≥n en formato de l√≠nea de tiempo\n",
    "if todos_los_resultados:\n",
    "    # Ordenar resultados por a√±o\n",
    "    todos_los_resultados.sort(key=lambda x: x['year'])\n",
    "    \n",
    "    num_imagenes = len(todos_los_resultados)\n",
    "    cols = 5  # N√∫mero de columnas en la visualizaci√≥n\n",
    "    rows = (num_imagenes + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, resultado in enumerate(todos_los_resultados):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Crear mapa de colores\n",
    "        mapa_coloreado = crear_mapa_coloreado(resultado['labels'], class_colors)\n",
    "        \n",
    "        ax.imshow(mapa_coloreado)\n",
    "        ax.set_title(f\"A√±o: {resultado['year']}\\\\nM√©todo: {resultado['method']}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # A√±adir estad√≠sticas de distribuci√≥n\n",
    "        stats_text = []\n",
    "        for j, name in enumerate(class_names, 1):\n",
    "            percentage = 100.0 * np.sum(resultado['labels'] == j) / resultado['labels'].size\n",
    "            stats_text.append(f\"{name[0]}: {percentage:.1f}%\")\n",
    "        \n",
    "        ax.text(0.5, -0.1, \" | \".join(stats_text), \n",
    "                ha='center', va='center', transform=ax.transAxes, fontsize=9)\n",
    "\n",
    "    # Ocultar ejes no utilizados\n",
    "    for i in range(num_imagenes, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    fig.suptitle(\"Evoluci√≥n de la Cobertura del Suelo a lo Largo del Tiempo\", fontsize=24, fontweight='bold')\n",
    "    \n",
    "    # Crear leyenda global\n",
    "    legend_elements = [Patch(facecolor=color, edgecolor='k', label=name) for name, color in zip(class_names, class_colors)]\n",
    "    fig.legend(handles=legend_elements, loc='lower center', ncol=3, fontsize=14, bbox_to_anchor=(0.5, -0.02))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Guardar la figura\n",
    "    timeline_path = figures_path / \"evolucion_temporal_segmentacion.png\"\n",
    "    fig.savefig(timeline_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\\\nüñºÔ∏è  Visualizaci√≥n de la evoluci√≥n guardada en: {timeline_path}\")\n",
    "else:\n",
    "    print(\"No se generaron resultados para visualizar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb2637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
